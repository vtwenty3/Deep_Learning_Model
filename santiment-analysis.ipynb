{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SET09122 Coursework C.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NXXN2nt9EmoJ",
        "XeAwGG5HDfxa",
        "bi5lrlr0Z-xG",
        "kwhH11hSDurJ",
        "piG5IMXDD8Oq",
        "qZ6qohPhEFYB",
        "qzCS6AdyEHS9",
        "YIdEK6PyEO4O",
        "fOOnkEyHhqhT",
        "_qZIFJRaEV1W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLTrLFdGZp2K"
      },
      "source": [
        "# Artificial Intelligence | Deep Learning Model | Text santiment Analysis \n",
        "### Author: Valentin Kisimov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXXN2nt9EmoJ"
      },
      "source": [
        "### Importing all the libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNT1USW6ZtgV"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6tkEriwZzr6",
        "outputId": "a359aeec-e09f-42f3-977d-408c28e7ccf4"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeAwGG5HDfxa"
      },
      "source": [
        "## The data have to be in the root folder of google drive to load correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNJ4hnZNZ167"
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/train.csv', names=['sentence', 'label'], sep=',')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/test.csv', names=['sentence', 'label'], sep=',')\n",
        "df_val = pd.read_csv('/content/drive/My Drive/val.csv', names=['sentence', 'label'], sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi5lrlr0Z-xG"
      },
      "source": [
        "## Simple Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJGC2UYyaAy5"
      },
      "source": [
        "df_train['sentence'] = df_train['sentence'].str.lower()\n",
        "df_train_pro = df_train['sentence'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "df_test['sentence'] = df_test['sentence'].str.lower()\n",
        "df_test_pro = df_test['sentence'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "df_val['sentence'] = df_val['sentence'].str.lower()\n",
        "df_val_pro = df_val['sentence'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwhH11hSDurJ"
      },
      "source": [
        "## Tokenizing, preparing the data for training and embedding numbers to each"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWyeNwd-aLsm",
        "outputId": "e2a83e4f-e987-4f0c-f341-6561e0bb9da5"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "\n",
        "max_words = 719\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "\n",
        "tokenized_train = tokenizer.fit_on_texts(df_train_pro)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(df_train_pro)\n",
        "sequences_test = tokenizer.texts_to_sequences(df_test_pro)\n",
        "sequences_val = tokenizer.texts_to_sequences(df_val_pro)\n",
        "\n",
        "\n",
        "X_train = pad_sequences(sequences_train)\n",
        "X_test = pad_sequences(sequences_test)\n",
        "X_val = pad_sequences(sequences_val)\n",
        "\n",
        "\n",
        "y_train = df_train['label'].values\n",
        "y_test = df_test['label'].values\n",
        "y_val = df_val['label'].values\n",
        "\n",
        "\n",
        "#print(X_train)\n",
        "print(X_test[1])\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0 ...  21 727  15]\n",
            "40420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfENQy_XVFjV"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piG5IMXDD8Oq"
      },
      "source": [
        "## Two functions used to display the results after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyqBk9nDqeKK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(training):\n",
        "# Plot history: MAE\n",
        "  plt.plot(training.history['val_loss'], label='Validation loss)')\n",
        "  plt.plot(training.history['accuracy'], label='Accuracy')\n",
        "  plt.title('Sentiment analysis')\n",
        "  plt.ylabel('value')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n",
        "def display_learning_curves(history):\n",
        "    fig, (ax1) = plt.subplots( figsize=(5, 5))\n",
        "\n",
        "    ax1.plot(history.history[\"loss\"])\n",
        "    ax1.plot(history.history[\"val_loss\"])\n",
        "    ax1.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ6qohPhEFYB"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzCS6AdyEHS9"
      },
      "source": [
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIzfKfTMUWab"
      },
      "source": [
        "\n",
        "def model_1():\n",
        "    embedding_dim = 64\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim)) #The embedding layer\n",
        "    model.add(layers.Bidirectional(layers.LSTM(12, dropout=0.6)))\n",
        "    model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model1 = model_1()\n",
        "training_1 = model1.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LsFdqRL87no",
        "outputId": "7bbab9fe-1185-4053-bfac-658cab38171e"
      },
      "source": [
        "results1 = model1.evaluate(X_val, y_val)\n",
        "print(\"test loss, test acc:\", results1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 133ms/step - loss: 0.5686 - accuracy: 0.7350\n",
            "test loss, test acc: [0.5685977339744568, 0.7350000143051147]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fwrGA1erUyg"
      },
      "source": [
        "display_learning_curves(training_1)\n",
        "plot_history(training_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D5a6llN6qQ8"
      },
      "source": [
        "plot_history(training_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIdEK6PyEO4O"
      },
      "source": [
        "### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7olyU7u9Bti"
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "def model_2():\n",
        "    embedding_dim = 64\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim)) #The embedding layer\n",
        "    layers.Dropout(0.2)\n",
        "    model.add(layers.Bidirectional(layers.LSTM(24, dropout=0.6)))\n",
        "    model.add(layers.Dense(1,activation='sigmoid'))\n",
        "   \n",
        "    print(model.summary())\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "model2 = model_2()\n",
        "training_2 = model2.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSTPKKcb-yat"
      },
      "source": [
        "results2 = model2.evaluate(X_val, y_val)\n",
        "print(\"test loss, test acc:\", results2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxbssvjNbGmw"
      },
      "source": [
        "display_learning_curves(training_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTxVjq-h0ctG"
      },
      "source": [
        "plot_history(training_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOOnkEyHhqhT"
      },
      "source": [
        "### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50OZISKQhQny"
      },
      "source": [
        "def model_3():\n",
        "    embedding_dim = 32\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim)) #The embedding layer\n",
        "    model.add(layers.Bidirectional(layers.LSTM(12, dropout=0.6)))\n",
        "    model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model3 = model_3()\n",
        "training_3 = model3.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWxh-jbJiPXm"
      },
      "source": [
        "results3 = model3.evaluate(X_val, y_val)\n",
        "print(\"test loss, test acc:\", results3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J--pDnNoiRMu"
      },
      "source": [
        "display_learning_curves(training_3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXkctzda6hGs"
      },
      "source": [
        "plot_history(training_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qZIFJRaEV1W"
      },
      "source": [
        "### Model 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcynSm1tKwN"
      },
      "source": [
        "def model_4():\n",
        "    embedding_dim = 32\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim)) #The embedding layer\n",
        "    model.add(layers.Bidirectional(layers.LSTM(16, dropout=0.6)))\n",
        "    model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model4 = model_4()\n",
        "training_4 = model4.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqMBjsK-jljM"
      },
      "source": [
        "results4 = model3.evaluate(X_val, y_val)\n",
        "print(\"test loss, test acc:\", results4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUBiRv05tX60"
      },
      "source": [
        "display_learning_curves(training_4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9da-saD6vv7"
      },
      "source": [
        "plot_history(training_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni9gmcvBEYSA"
      },
      "source": [
        "Thank you for the oppurunity to learn all of this! I hope you liked my models and report! "
      ]
    }
  ]
}